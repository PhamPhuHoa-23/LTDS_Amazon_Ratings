{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recommendation System Modeling - Amazon Beauty Ratings\n",
        "\n",
        "This notebook builds and evaluates recommendation systems:\n",
        "- Popularity-based recommendations (baseline)\n",
        "- User-based collaborative filtering\n",
        "- Item-based collaborative filtering\n",
        "- Matrix Factorization (SVD)\n",
        "- Matrix Factorization with SGD\n",
        "- Model comparison and evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Load Processed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.abspath('../src'))\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from data_loader import load_csv_numpy\n",
        "from similarity import (\n",
        "    create_user_item_matrix, cosine_similarity_matrix,\n",
        "    pearson_correlation, find_top_k_similar\n",
        ")\n",
        "from models import (\n",
        "    svd_numpy, matrix_factorization_sgd, predict_rating,\n",
        "    rmse, mae, precision_at_k, recall_at_k, hit_rate,\n",
        "    train_test_split_numpy\n",
        ")\n",
        "\n",
        "np.random.seed(42)\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed data not found. Loading raw data and filtering...\n",
            "Filtered data: (394908,)\n",
            "Unique users: 52,204\n",
            "Unique products: 57,289\n",
            "Total ratings: 394,908\n"
          ]
        }
      ],
      "source": [
        "base_dir = os.path.dirname(os.path.dirname(os.path.abspath('')))\n",
        "processed_path = os.path.join(base_dir, 'data', 'processed', 'filtered_data.npy')\n",
        "raw_path = os.path.join(base_dir, 'data', 'raw', 'ratings_Beauty.csv')\n",
        "\n",
        "try:\n",
        "    data = np.load(processed_path, allow_pickle=True)\n",
        "    print(f\"Loaded processed data: {data.shape}\")\n",
        "except:\n",
        "    print(\"Processed data not found. Loading raw data and filtering...\")\n",
        "    data, _ = load_csv_numpy(raw_path)\n",
        "    from data_processing import filter_by_min_ratings\n",
        "    data = filter_by_min_ratings(data, min_user_ratings=5, min_product_ratings=5)\n",
        "    print(f\"Filtered data: {data.shape}\")\n",
        "\n",
        "print(f\"Unique users: {len(np.unique(data['UserId'])):,}\")\n",
        "print(f\"Unique products: {len(np.unique(data['ProductId'])):,}\")\n",
        "print(f\"Total ratings: {len(data):,}\")\n",
        "\n",
        "print(\"\\nSampling data to avoid memory issues...\")\n",
        "sample_size = 5000\n",
        "if len(data) > sample_size:\n",
        "    sample_indices = np.random.choice(len(data), sample_size, replace=False)\n",
        "    data_sample = data[sample_indices]\n",
        "    print(f\"Using sample of {sample_size} ratings\")\n",
        "else:\n",
        "    data_sample = data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create User-Item Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User-item matrix shape: (52204, 57289)\n",
            "Sparsity: 99.99%\n",
            "Density: 0.0132%\n"
          ]
        }
      ],
      "source": [
        "user_ids = data_sample['UserId']\n",
        "product_ids = data_sample['ProductId']\n",
        "ratings = data_sample['Rating']\n",
        "\n",
        "matrix, user_map, product_map = create_user_item_matrix(user_ids, product_ids, ratings)\n",
        "\n",
        "print(f\"User-item matrix shape: {matrix.shape}\")\n",
        "print(f\"Sparsity: {(1 - np.count_nonzero(matrix) / matrix.size) * 100:.2f}%\")\n",
        "print(f\"Density: {(np.count_nonzero(matrix) / matrix.size) * 100:.4f}%\")\n",
        "\n",
        "inverse_user_map = {v: k for k, v in user_map.items()}\n",
        "inverse_product_map = {v: k for k, v in product_map.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Popularity-Based Recommendations (Baseline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Top 20 Most Popular Products ===\n",
            "\n",
            " 1. Product B000ZMBSPE: 539 ratings\n",
            " 2. Product B0043OYFKU: 539 ratings\n",
            " 3. Product B004OHQR1Q: 518 ratings\n",
            " 4. Product B000142FVW: 458 ratings\n",
            " 5. Product B0069FDR96: 453 ratings\n",
            " 6. Product B00150LT40: 443 ratings\n",
            " 7. Product B001MA0QY2: 434 ratings\n",
            " 8. Product B003V265QW: 416 ratings\n",
            " 9. Product B006L1DNWY: 379 ratings\n",
            "10. Product B008U1Q4DI: 363 ratings\n",
            "\n",
            "This is the baseline recommendation for new users (cold start problem).\n"
          ]
        }
      ],
      "source": [
        "product_ratings_count = np.sum(matrix > 0, axis=0)\n",
        "top_n = 20\n",
        "top_products_idx = np.argsort(product_ratings_count)[-top_n:][::-1]\n",
        "\n",
        "print(\"=== Top 20 Most Popular Products ===\\n\")\n",
        "for i, idx in enumerate(top_products_idx[:10], 1):\n",
        "    product_id = inverse_product_map[idx]\n",
        "    count = product_ratings_count[idx]\n",
        "    print(f\"{i:2d}. Product {product_id}: {count:,} ratings\")\n",
        "\n",
        "print(\"\\nThis is the baseline recommendation for new users (cold start problem).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. User-Based Collaborative Filtering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== User-Based Collaborative Filtering ===\n",
            "\n",
            "Computing user-user similarity matrix...\n"
          ]
        },
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 22.3 GiB for an array with shape (57289, 52204) and data type float64",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== User-Based Collaborative Filtering ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mComputing user-user similarity matrix...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m user_similarity = cosine_similarity_matrix(matrix, axis=\u001b[32m0\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUser similarity matrix shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_similarity.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m test_user_idx = \u001b[32m0\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\Downloads\\Lab2DS\\src\\similarity.py:63\u001b[39m, in \u001b[36mcosine_similarity_matrix\u001b[39m\u001b[34m(matrix, axis)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m:\n\u001b[32m     61\u001b[39m     matrix = matrix.T\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m norms = np.linalg.norm(matrix, axis=\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     64\u001b[39m norms[norms == \u001b[32m0\u001b[39m] = \u001b[32m1\u001b[39m\n\u001b[32m     66\u001b[39m normalized = matrix / norms\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\admin\\miniconda3\\Lib\\site-packages\\numpy\\linalg\\linalg.py:2582\u001b[39m, in \u001b[36mnorm\u001b[39m\u001b[34m(x, ord, axis, keepdims)\u001b[39m\n\u001b[32m   2579\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m add.reduce(\u001b[38;5;28mabs\u001b[39m(x), axis=axis, keepdims=keepdims)\n\u001b[32m   2580\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mord\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mord\u001b[39m == \u001b[32m2\u001b[39m:\n\u001b[32m   2581\u001b[39m     \u001b[38;5;66;03m# special case for speedup\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2582\u001b[39m     s = (x.conj() * x).real\n\u001b[32m   2583\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n\u001b[32m   2584\u001b[39m \u001b[38;5;66;03m# None of the str-type keywords for ord ('fro', 'nuc')\u001b[39;00m\n\u001b[32m   2585\u001b[39m \u001b[38;5;66;03m# are valid for vectors\u001b[39;00m\n",
            "\u001b[31mMemoryError\u001b[39m: Unable to allocate 22.3 GiB for an array with shape (57289, 52204) and data type float64"
          ]
        }
      ],
      "source": [
        "print(\"=== User-Based Collaborative Filtering ===\\n\")\n",
        "print(\"Using sample matrix to avoid memory issues...\")\n",
        "\n",
        "sample_size = min(1000, matrix.shape[0])\n",
        "sample_matrix = matrix[:sample_size, :]\n",
        "print(f\"Sample matrix shape: {sample_matrix.shape}\")\n",
        "\n",
        "user_similarity = cosine_similarity_matrix(sample_matrix, axis=0)\n",
        "print(f\"User similarity matrix shape: {user_similarity.shape}\")\n",
        "\n",
        "test_user_idx = 0\n",
        "top_k_users_idx, top_k_scores = find_top_k_similar(user_similarity, test_user_idx, k=5)\n",
        "\n",
        "print(f\"\\nTop 5 similar users to user {test_user_idx}:\")\n",
        "for i, (user_idx, score) in enumerate(zip(top_k_users_idx, top_k_scores), 1):\n",
        "    print(f\"  {i}. User {user_idx}: similarity = {score:.4f}\")\n",
        "\n",
        "print(\"\\nRecommendations based on similar users' preferences...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Item-Based Collaborative Filtering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Item-Based Collaborative Filtering ===\\n\")\n",
        "print(\"Using sample matrix to avoid memory issues...\")\n",
        "\n",
        "item_sample_size = min(1000, matrix.shape[1])\n",
        "item_sample_matrix = matrix[:, :item_sample_size]\n",
        "print(f\"Item sample matrix shape: {item_sample_matrix.shape}\")\n",
        "\n",
        "item_similarity = cosine_similarity_matrix(item_sample_matrix, axis=1)\n",
        "print(f\"Item similarity matrix shape: {item_similarity.shape}\")\n",
        "\n",
        "test_product_idx = 0\n",
        "top_k_products_idx, top_k_scores = find_top_k_similar(item_similarity, test_product_idx, k=5)\n",
        "\n",
        "print(f\"\\nTop 5 similar products to product {test_product_idx}:\")\n",
        "for i, (prod_idx, score) in enumerate(zip(top_k_products_idx, top_k_scores), 1):\n",
        "    product_id = inverse_product_map[prod_idx]\n",
        "    print(f\"  {i}. Product {product_id}: similarity = {score:.4f}\")\n",
        "\n",
        "print(\"\\nRecommendations: 'Users who liked this also liked...'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Matrix Factorization - SVD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== SVD-based Matrix Factorization ===\\n\")\n",
        "\n",
        "k_factors = 10\n",
        "print(f\"Decomposing matrix with {k_factors} latent factors...\")\n",
        "\n",
        "svd_sample_size = min(500, matrix.shape[0], matrix.shape[1])\n",
        "svd_sample_matrix = matrix[:svd_sample_size, :svd_sample_size]\n",
        "print(f\"Using sample matrix: {svd_sample_matrix.shape}\")\n",
        "\n",
        "U_k, Sigma_k, Vt_k = svd_numpy(svd_sample_matrix.T, k_factors)\n",
        "print(f\"U shape: {U_k.shape}, Sigma shape: {Sigma_k.shape}, Vt shape: {Vt_k.shape}\")\n",
        "\n",
        "reconstructed = U_k @ np.diag(Sigma_k) @ Vt_k\n",
        "print(f\"Reconstructed matrix shape: {reconstructed.shape}\")\n",
        "\n",
        "print(\"\\nUsing correlation of decomposed matrix for recommendations...\")\n",
        "correlation_matrix = np.corrcoef(reconstructed)\n",
        "print(f\"Correlation matrix shape: {correlation_matrix.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Matrix Factorization - SGD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Matrix Factorization with SGD ===\\n\")\n",
        "print(\"Note: This may take a while for large matrices...\")\n",
        "\n",
        "sample_size = min(1000, matrix.shape[0])\n",
        "sample_matrix = matrix[:sample_size, :sample_size]\n",
        "print(f\"Using sample matrix: {sample_matrix.shape} for demonstration\")\n",
        "\n",
        "K = 10\n",
        "steps = 100\n",
        "print(f\"Training with {steps} iterations, {K} latent factors...\")\n",
        "\n",
        "P, Q = matrix_factorization_sgd(sample_matrix, K, steps=steps, alpha=0.002, beta=0.02)\n",
        "print(f\"P shape: {P.shape}, Q shape: {Q.shape}\")\n",
        "\n",
        "print(\"\\nPredicting ratings for sample user-item pairs...\")\n",
        "test_predictions = []\n",
        "for i in range(min(10, sample_matrix.shape[0])):\n",
        "    for j in range(min(10, sample_matrix.shape[1])):\n",
        "        if sample_matrix[i, j] > 0:\n",
        "            pred = predict_rating(P, Q, i, j)\n",
        "            test_predictions.append((sample_matrix[i, j], pred))\n",
        "\n",
        "if test_predictions:\n",
        "    true_vals = np.array([p[0] for p in test_predictions])\n",
        "    pred_vals = np.array([p[1] for p in test_predictions])\n",
        "    print(f\"Sample RMSE: {rmse(true_vals, pred_vals):.4f}\")\n",
        "    print(f\"Sample MAE: {mae(true_vals, pred_vals):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Model Comparison and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Model Comparison ===\\n\")\n",
        "\n",
        "print(\"Evaluation Metrics Summary:\")\n",
        "print(\"\\n1. Popularity-Based:\")\n",
        "print(\"   - Simple and fast\")\n",
        "print(\"   - Good for cold start\")\n",
        "print(\"   - No personalization\")\n",
        "\n",
        "print(\"\\n2. User-Based CF:\")\n",
        "print(\"   - Personalized recommendations\")\n",
        "print(\"   - Computationally expensive\")\n",
        "print(\"   - Requires user similarity matrix\")\n",
        "\n",
        "print(\"\\n3. Item-Based CF:\")\n",
        "print(\"   - More stable than user-based\")\n",
        "print(\"   - Better scalability\")\n",
        "print(\"   - Good for sparse data\")\n",
        "\n",
        "print(\"\\n4. SVD:\")\n",
        "print(\"   - Dimensionality reduction\")\n",
        "print(\"   - Captures latent factors\")\n",
        "print(\"   - Efficient for large matrices\")\n",
        "\n",
        "print(\"\\n5. Matrix Factorization (SGD):\")\n",
        "print(\"   - Most flexible\")\n",
        "print(\"   - Can handle missing data\")\n",
        "print(\"   - Requires tuning hyperparameters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Recommendation Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Recommendation Example ===\\n\")\n",
        "\n",
        "example_user_idx = 0\n",
        "user_ratings = matrix[example_user_idx, :]\n",
        "rated_products = np.where(user_ratings > 0)[0]\n",
        "\n",
        "print(f\"User {example_user_idx} has rated {len(rated_products)} products\")\n",
        "\n",
        "if len(rated_products) > 0:\n",
        "    print(\"\\nUser's rated products (sample):\")\n",
        "    for idx in rated_products[:5]:\n",
        "        product_id = inverse_product_map[idx]\n",
        "        rating = user_ratings[idx]\n",
        "        print(f\"  Product {product_id}: {rating:.1f} stars\")\n",
        "    \n",
        "    print(\"\\nRecommendations using item-based CF:\")\n",
        "    if len(rated_products) > 0 and item_similarity.shape[0] > 0:\n",
        "        similar_items = []\n",
        "        for rated_idx in rated_products[:3]:\n",
        "            if rated_idx < item_similarity.shape[0]:\n",
        "                top_items, _ = find_top_k_similar(item_similarity, rated_idx, k=3)\n",
        "                similar_items.extend(top_items)\n",
        "        \n",
        "        unique_recommendations = np.unique(similar_items)\n",
        "        recommendations = [idx for idx in unique_recommendations if idx not in rated_products][:10]\n",
        "        \n",
        "        print(f\"Top 10 recommended products:\")\n",
        "        for i, idx in enumerate(recommendations[:10], 1):\n",
        "            if idx < len(inverse_product_map):\n",
        "                product_id = inverse_product_map[idx]\n",
        "                print(f\"  {i}. Product {product_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Key Findings and Next Steps\n",
        "\n",
        "### Findings:\n",
        "1. **Sparsity Challenge**: User-item matrix is highly sparse (>99%)\n",
        "2. **Popularity Baseline**: Simple but effective for cold start\n",
        "3. **Collaborative Filtering**: Provides personalization but computationally expensive\n",
        "4. **Matrix Factorization**: Best balance of accuracy and efficiency\n",
        "\n",
        "### Next Steps:\n",
        "- Fine-tune hyperparameters (K factors, learning rate, regularization)\n",
        "- Implement hybrid approaches\n",
        "- Add content-based features if available\n",
        "- Evaluate on held-out test set\n",
        "- Measure diversity and coverage metrics\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
