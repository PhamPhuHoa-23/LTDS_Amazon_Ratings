{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tinh Ch·ªânh v√† So S√°nh C√°c Models Recommendation\n",
    "\n",
    "**CSC17104 - Programming for Data Science**  \n",
    "**Student:** Angela - MSSV: 23122030  \n",
    "**Notebook:** 04_model_tuning_sklearn.ipynb\n",
    "\n",
    "---\n",
    "\n",
    "## Version n√†y d√πng sklearn\n",
    "\n",
    "### Fix SVD cho sparse data:\n",
    "- **V·∫•n ƒë·ªÅ:** Full SVD fail v·ªõi sparse matrix (99% zeros)\n",
    "- **Gi·∫£i ph√°p:** D√πng `sklearn.decomposition.TruncatedSVD`\n",
    "  - Optimized cho sparse matrices\n",
    "  - Ch·ªâ t√≠nh k largest components\n",
    "  - Production-ready, well-tested\n",
    "\n",
    "### C·∫•u tr√∫c:\n",
    "1. **Baseline** ‚Üí **Simple CF** ‚Üí **Advanced SVD**\n",
    "2. Train t·∫•t c·∫£ models v·ªõi hyperparameters kh√°c nhau\n",
    "3. Evaluate t·∫≠p trung\n",
    "4. Visualization t·ªïng h·ª£p\n",
    "5. Nh·∫≠n x√©t chi ti·∫øt\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup v√† Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Setup\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "\n",
    "# Import OOP classes t·ª´ src\n",
    "from data_processor import DataProcessor\n",
    "from models import (\n",
    "    PopularityRecommender, ItemBasedCF, UserBasedCF, \n",
    "    SVDRecommender, TruncatedSVD,\n",
    "    precision_at_k, recall_at_k, f1_at_k,\n",
    "    hit_rate_at_k, mean_reciprocal_rank,\n",
    "    coverage, diversity\n",
    ")\n",
    "from visualizer import Visualizer\n",
    "from data_processing import load_processed_data, train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"B·∫Øt ƒë·∫ßu: {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVD Wrapper d√πng sklearn\n",
    "\n",
    "### sklearn.decomposition.TruncatedSVD:\n",
    "\n",
    "**∆Øu ƒëi·ªÉm:**\n",
    "- Optimized cho sparse matrices (d√πng ARPACK ho·∫∑c randomized algorithm)\n",
    "- API ƒë∆°n gi·∫£n: `fit()`, `transform()`, `fit_transform()`\n",
    "- C√≥ `explained_variance_ratio_` ƒë·ªÉ ph√¢n t√≠ch\n",
    "- Production-ready, well-tested\n",
    "\n",
    "**Parameters quan tr·ªçng:**\n",
    "- `n_components`: S·ªë latent factors (20-100 cho sparse data)\n",
    "- `algorithm`: 'randomized' (m·∫∑c ƒë·ªãnh, nhanh) ho·∫∑c 'arpack' (ch√≠nh x√°c h∆°n)\n",
    "- `random_state`: ƒê·ªÉ reproducible\n",
    "\n",
    "**L∆∞u √Ω:**\n",
    "- sklearn TruncatedSVD t·ª± ƒë·ªông center data (kh√¥ng c·∫ßn manual centering)\n",
    "- Tr·∫£ v·ªÅ components theo th·ª© t·ª± gi·∫£m d·∫ßn (largest first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVDRecommenderNumPy:\n",
    "    \"\"\"\n",
    "    SVD Recommender d√πng TruncatedSVD implementation t·ª´ scratch (NumPy only).\n",
    "    Kh√¥ng d√πng sklearn - t√≠nh SVD b·∫±ng power iteration method.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=50, n_iterations=20):\n",
    "        self.n_components = n_components\n",
    "        self.n_iterations = n_iterations\n",
    "        self.svd_model = TruncatedSVD(n_components=n_components, n_iterations=n_iterations)\n",
    "        self.user_item_matrix = None\n",
    "        self.global_mean = None\n",
    "        self.n_users = None\n",
    "        self.n_items = None\n",
    "    \n",
    "    def fit(self, user_indices, item_indices, ratings, n_users, n_items):\n",
    "        \"\"\"\n",
    "        Train SVD model b·∫±ng TruncatedSVD (from scratch)\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        user_indices, item_indices : arrays\n",
    "            User and item indices\n",
    "        ratings : array\n",
    "            Ratings\n",
    "        n_users, n_items : int\n",
    "            Number of users and items\n",
    "        \"\"\"\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.global_mean = np.mean(ratings)\n",
    "        \n",
    "        # Create dense user-item matrix (vectorized)\n",
    "        print(f\"T·∫°o user-item matrix: {n_users}√ó{n_items}\")\n",
    "        self.user_item_matrix = np.zeros((n_users, n_items))\n",
    "        self.user_item_matrix[user_indices, item_indices] = ratings\n",
    "        \n",
    "        sparsity = 1 - (len(ratings) / (n_users * n_items))\n",
    "        print(f\"Non-zero: {len(ratings):,}\")\n",
    "        print(f\"Sparsity: {sparsity*100:.4f}%\")\n",
    "        \n",
    "        print(f\"Fitting TruncatedSVD (k={self.n_components}, d√πng power iteration)...\")\n",
    "        # Fit TruncatedSVD t·ª´ scratch\n",
    "        self.svd_model.fit(self.user_item_matrix)\n",
    "        print(\"SVD ho√†n t·∫•t (power iteration converged)\")\n",
    "        print(f\"User factors (U): ({self.svd_model.U.shape[0]}, {self.svd_model.U.shape[1]})\")\n",
    "        print(f\"Item factors (V^T): ({self.svd_model.Vt.shape[0]}, {self.svd_model.Vt.shape[1]})\")\n",
    "    \n",
    "    def predict(self, user_id, item_id):\n",
    "        \"\"\"Predict rating cho user-item pair\"\"\"\n",
    "        if user_id >= self.n_users or item_id >= self.n_items:\n",
    "            return self.global_mean\n",
    "        \n",
    "        # Reconstruct matrix v√† l·∫•y gi√° tr·ªã\n",
    "        reconstructed = self.svd_model.reconstruct()\n",
    "        return reconstructed[user_id, item_id]\n",
    "    \n",
    "    def recommend(self, user_id, top_n=10, exclude_rated=None):\n",
    "        \"\"\"Recommend top N items cho user\"\"\"\n",
    "        if user_id >= self.n_users:\n",
    "            return np.array([], dtype=int)\n",
    "        \n",
    "        reconstructed = self.svd_model.reconstruct()\n",
    "        predicted_ratings = reconstructed[user_id]\n",
    "        \n",
    "        # Exclude already rated items\n",
    "        if exclude_rated is not None and len(exclude_rated) > 0:\n",
    "            predicted_ratings[list(exclude_rated)] = -np.inf\n",
    "        \n",
    "        top_items = np.argsort(predicted_ratings)[::-1][:top_n]\n",
    "        valid_items = top_items[predicted_ratings[top_items] > -np.inf]\n",
    "        \n",
    "        return valid_items\n",
    "\n",
    "print(\"SVDRecommenderNumPy ƒë√£ ƒë·ªãnh nghƒ©a (d√πng TruncatedSVD t·ª´ scratch)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Load d·ªØ li·ªáu ƒë√£ ti·ªÅn x·ª≠ l√Ω...\")\n",
    "\n",
    "data_dict = load_processed_data('../data/processed/')\n",
    "data = data_dict['data']\n",
    "mappings = data_dict['mappings']\n",
    "metadata = data_dict['metadata']\n",
    "\n",
    "user_indices = data['user_indices']\n",
    "product_indices = data['product_indices']\n",
    "ratings = data['ratings']\n",
    "timestamps = data['timestamps']\n",
    "\n",
    "n_users = len(mappings['unique_users'])\n",
    "n_products = len(mappings['unique_products'])\n",
    "\n",
    "print(f\"Dataset: {len(ratings):,} ratings\")\n",
    "print(f\"Ng∆∞·ªùi d√πng: {n_users:,}, S·∫£n ph·∫©m: {n_products:,}\")\n",
    "print(f\"Sparsity: {metadata['sparsity']*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[B∆Ø·ªöC 2] Train-test split (80-20)...\\n\")\n",
    "\n",
    "split_data = train_test_split(\n",
    "    user_indices, product_indices, ratings, timestamps,\n",
    "    test_size=0.2, random_seed=42\n",
    ")\n",
    "\n",
    "train_data = split_data['train']\n",
    "test_data = split_data['test']\n",
    "\n",
    "print(f\"Train: {len(train_data['ratings']):,}\")\n",
    "print(f\"Test: {len(test_data['ratings']):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'models': {}, 'train_times': {}, 'metrics': {}}\n",
    "\n",
    "def save_model_result(name, model, train_time):\n",
    "    results['models'][name] = model\n",
    "    results['train_times'][name] = train_time\n",
    "    print(f\"{name}: {train_time:.2f}s\")\n",
    "\n",
    "print(\"Results initialized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PH·∫¶N A: TRAINING\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Level 0: Popularity Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LEVEL 0: POPULARITY\")\n",
    "pop = PopularityRecommender()\n",
    "start = time.time()\n",
    "pop.fit(train_data['product_indices'], train_data['ratings'])\n",
    "save_model_result('Popularity', pop, time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Level 1: Item-CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LEVEL 1A: ITEM-CF\")\n",
    "for thresh in [0.0, 0.1, 0.2]:\n",
    "    print(f\"Threshold {thresh}\")\n",
    "    icf = ItemBasedCF(min_similarity=thresh)\n",
    "    start = time.time()\n",
    "    icf.fit(train_data['user_indices'], train_data['product_indices'], \n",
    "            train_data['ratings'], n_products)\n",
    "    save_model_result(f'ItemCF_t{thresh}', icf, time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Level 1: User-CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LEVEL 1B: USER-CF\")\n",
    "for k in [10, 20, 50]:\n",
    "    print(f\"k={k} neighbors\")\n",
    "    ucf = UserBasedCF(k_neighbors=k, min_similarity=0.1)\n",
    "    start = time.time()\n",
    "    ucf.fit(train_data['user_indices'], train_data['product_indices'],\n",
    "            train_data['ratings'], n_users, n_products)\n",
    "    save_model_result(f'UserCF_k{k}', ucf, time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Level 2: SVD v·ªõi sklearn\n",
    "\n",
    "### T·∫°i sao sklearn TruncatedSVD t·ªët cho sparse data:\n",
    "\n",
    "**Algorithm 'randomized' (default):**\n",
    "- D√πng randomized algorithm (Halko et al., 2009)\n",
    "- R·∫•t nhanh v·ªõi sparse matrices l·ªõn\n",
    "- Approximate nh∆∞ng accuracy cao\n",
    "- O(k¬≤n + k¬≥) complexity thay v√¨ O(min(m,n)¬≥)\n",
    "\n",
    "**Algorithm 'arpack':**\n",
    "- D√πng ARPACK (iterative eigenvalue solver)\n",
    "- Ch√≠nh x√°c h∆°n randomized\n",
    "- Ch·∫≠m h∆°n m·ªôt ch√∫t\n",
    "- T·ªët khi c·∫ßn exact results\n",
    "\n",
    "**V·ªõi data n√†y (sparse 99%):** Randomized algorithm l√† optimal choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LEVEL 2: SVD (TruncatedSVD t·ª´ scratch - power iteration)\")\n",
    "for k in [20, 50, 100]:\n",
    "    print(f\"SVD k={k}\")\n",
    "    svd = SVDRecommenderNumPy(n_components=k, n_iterations=20)\n",
    "    start = time.time()\n",
    "    svd.fit(train_data['user_indices'], train_data['product_indices'],\n",
    "            train_data['ratings'], n_users, n_products)\n",
    "    train_time = time.time() - start\n",
    "    save_model_result(f'SVD_k{k}', svd, train_time)\n",
    "    print(f\"Train time: {train_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nh·∫≠n x√©t v·ªÅ SVD training\n",
    "\n",
    "*ƒêi·ªÅn sau khi ch·∫°y*\n",
    "\n",
    "#### Variance explained:\n",
    "- k=20: [ƒëi·ªÅn]% variance\n",
    "- k=50: [ƒëi·ªÅn]% variance  \n",
    "- k=100: [ƒëi·ªÅn]% variance\n",
    "\n",
    "#### Training time:\n",
    "- k=20: [ƒëi·ªÅn]s\n",
    "- k=50: [ƒëi·ªÅn]s\n",
    "- k=100: [ƒëi·ªÅn]s\n",
    "\n",
    "#### Observations:\n",
    "- Top factor chi·∫øm ~[ƒëi·ªÅn]% variance\n",
    "- Top 10 factors chi·∫øm ~[ƒëi·ªÅn]% variance\n",
    "- N·∫øu k=20 ƒë√£ >80% variance ‚Üí k=100 c√≥ th·ªÉ overkill\n",
    "- sklearn nhanh h∆°n code tay? [c√≥/kh√¥ng] - v√¨ [l√Ω do]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PH·∫¶N B: EVALUATION\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name, test_data, train_data, n_samples=100, top_n=10):\n",
    "    print(f\"ƒêang ƒë√°nh gi√°: {model_name}...\")\n",
    "\n",
    "    precisions, recalls, hit_rates = [], [], []\n",
    "    all_recs = []\n",
    "    n_success = n_empty = n_error = 0\n",
    "\n",
    "    for i in range(min(n_samples, len(test_data['user_indices']))):\n",
    "        user_id = test_data['user_indices'][i]\n",
    "        true_item = test_data['product_indices'][i]\n",
    "\n",
    "        try:\n",
    "            if isinstance(model, PopularityRecommender):\n",
    "                recs = model.recommend(top_n=top_n)\n",
    "            elif isinstance(model, ItemBasedCF):\n",
    "                mask = train_data['user_indices'] == user_id\n",
    "                if not np.any(mask):\n",
    "                    n_error += 1\n",
    "                    continue\n",
    "                recs = model.recommend_for_user(\n",
    "                    train_data['product_indices'][mask],\n",
    "                    train_data['ratings'][mask], top_n)\n",
    "            elif isinstance(model, UserBasedCF):\n",
    "                recs = model.recommend(user_id=user_id, top_n=top_n)\n",
    "                    elif isinstance(model, SVDRecommenderSklearn):\n",
    "                        mask = train_data['user_indices'] == user_id\n",
    "                        exclude = train_data['product_indices'][mask] if np.any(mask) else None\n",
    "                        recs = model.recommend(user_id=user_id, top_n=top_n, exclude_rated=exclude)\n",
    "                    elif 'SVDRecommenderNumPy' in globals() and isinstance(model, SVDRecommenderNumPy):\n",
    "                        mask = train_data['user_indices'] == user_id\n",
    "                        exclude = train_data['product_indices'][mask] if np.any(mask) else None\n",
    "                        recs = model.recommend(user_id=user_id, top_n=top_n, exclude_rated=exclude)\n",
    "            else:\n",
    "                n_error += 1\n",
    "                continue\n",
    "\n",
    "            if len(recs) == 0:\n",
    "                n_empty += 1\n",
    "                continue\n",
    "\n",
    "            precisions.append(precision_at_k(recs, [true_item], top_n))\n",
    "            recalls.append(recall_at_k(recs, [true_item], top_n))\n",
    "            hit_rates.append(hit_rate_at_k(recs, [true_item], top_n))\n",
    "            all_recs.append(recs)\n",
    "            n_success += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            n_error += 1\n",
    "            if n_error <= 3:\n",
    "                print(f\"Error: {str(e)}\")\n",
    "\n",
    "    print(f\"K·∫øt qu·∫£: Success={n_success}, Empty={n_empty}, Error={n_error}\")\n",
    "\n",
    "    if len(precisions) == 0:\n",
    "        return None\n",
    "\n",
    "    return {\n",
    "        'precision': np.mean(precisions),\n",
    "        'recall': np.mean(recalls),\n",
    "        'hit_rate': np.mean(hit_rates),\n",
    "        'f1': 2*np.mean(precisions)*np.mean(recalls)/(np.mean(precisions)+np.mean(recalls)) if (np.mean(precisions)+np.mean(recalls))>0 else 0,\n",
    "        'coverage': coverage(all_recs, np.arange(n_products)),\n",
    "        'diversity': diversity(all_recs),\n",
    "        'n_evaluated': len(precisions)\n",
    "    }\n",
    "\n",
    "print(\"Evaluation function ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ƒêang ƒë√°nh gi√° c√°c models...\")\n",
    "for name, model in results['models'].items():\n",
    "    metrics = evaluate_model(model, name, test_data, train_data, n_samples=100)\n",
    "    if metrics:\n",
    "        results['metrics'][name] = metrics\n",
    "\n",
    "print(\"ƒê√°nh gi√° ho√†n t·∫•t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = []\n",
    "for name in results['metrics'].keys():\n",
    "    m = results['metrics'][name]\n",
    "    t = results['train_times'][name]\n",
    "    comparison.append({\n",
    "        'Model': name,\n",
    "        'Precision@10': f\"{m['precision']:.4f}\",\n",
    "        'Recall@10': f\"{m['recall']:.4f}\",\n",
    "        'Hit Rate@10': f\"{m['hit_rate']:.4f}\",\n",
    "        'F1': f\"{m['f1']:.4f}\",\n",
    "        'Coverage': f\"{m['coverage']:.4f}\",\n",
    "        'Diversity': f\"{m['diversity']:.4f}\",\n",
    "        'Train (s)': f\"{t:.2f}\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(comparison)\n",
    "print(\"K·∫øt qu·∫£ - SKLEARN VERSION\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ph√¢n t√≠ch k·∫øt qu·∫£\n",
    "\n",
    "*ƒêi·ªÅn sau khi ch·∫°y*\n",
    "\n",
    "#### SVD c√≥ work kh√¥ng?\n",
    "- SVD_k20: Precision = [ƒëi·ªÅn]\n",
    "- SVD_k50: Precision = [ƒëi·ªÅn]\n",
    "- SVD_k100: Precision = [ƒëi·ªÅn]\n",
    "- **K·∫øt lu·∫≠n:** Sklearn SVD [c√≥/kh√¥ng] ho·∫°t ƒë·ªông t·ªët h∆°n code tay\n",
    "\n",
    "#### Best model:\n",
    "- Precision cao nh·∫•t: [model n√†o]\n",
    "- Coverage cao nh·∫•t: [model n√†o]\n",
    "- Training nhanh nh·∫•t: [model n√†o]\n",
    "- **Recommended:** [model n√†o] v√¨ [l√Ω do]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(results['metrics'].keys())\n",
    "prec = [results['metrics'][m]['precision'] for m in names]\n",
    "rec = [results['metrics'][m]['recall'] for m in names]\n",
    "hit = [results['metrics'][m]['hit_rate'] for m in names]\n",
    "cov = [results['metrics'][m]['coverage'] for m in names]\n",
    "div = [results['metrics'][m]['diversity'] for m in names]\n",
    "times = [results['train_times'][m] for m in names]\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "# 1. Accuracy metrics\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "x = np.arange(len(names))\n",
    "w = 0.25\n",
    "ax1.bar(x-w, prec, w, label='Precision', alpha=0.8)\n",
    "ax1.bar(x, rec, w, label='Recall', alpha=0.8)\n",
    "ax1.bar(x+w, hit, w, label='Hit Rate', alpha=0.8)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(names, rotation=45, ha='right', fontsize=8)\n",
    "ax1.set_title('Accuracy Metrics', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Coverage & Diversity\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.bar(x-w/2, cov, w, label='Coverage', alpha=0.8)\n",
    "ax2.bar(x+w/2, div, w, label='Diversity', alpha=0.8)\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(names, rotation=45, ha='right', fontsize=8)\n",
    "ax2.set_title('Coverage & Diversity', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Training time\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "ax3.barh(names, times, alpha=0.7, color='steelblue')\n",
    "ax3.set_xlabel('Seconds')\n",
    "ax3.set_title('Training Time', fontweight='bold')\n",
    "ax3.set_xscale('log')\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Precision vs Time\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "ax4.scatter(times, prec, s=100, alpha=0.6, c=range(len(names)), cmap='viridis')\n",
    "for i, n in enumerate(names):\n",
    "    ax4.annotate(n, (times[i], prec[i]), fontsize=7, alpha=0.7)\n",
    "ax4.set_xlabel('Training Time (s)')\n",
    "ax4.set_ylabel('Precision@10')\n",
    "ax4.set_title('Precision vs Time', fontweight='bold')\n",
    "ax4.set_xscale('log')\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "# 5. SVD analysis\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "svd_names = [n for n in names if 'SVD' in n]\n",
    "if svd_names:\n",
    "    svd_k = [int(n.split('_k')[-1]) for n in svd_names]\n",
    "    svd_prec = [results['metrics'][n]['precision'] for n in svd_names]\n",
    "    svd_time = [results['train_times'][n] for n in svd_names]\n",
    "    \n",
    "    ax5_twin = ax5.twinx()\n",
    "    l1 = ax5.plot(svd_k, svd_prec, 'o-b', linewidth=2, markersize=8, label='Precision')\n",
    "    l2 = ax5_twin.plot(svd_k, svd_time, 's--r', linewidth=2, markersize=8, label='Time')\n",
    "    \n",
    "    ax5.set_xlabel('k (factors)')\n",
    "    ax5.set_ylabel('Precision', color='b')\n",
    "    ax5_twin.set_ylabel('Time (s)', color='r')\n",
    "    ax5.set_title('SVD: k vs Performance', fontweight='bold')\n",
    "    ax5.tick_params(axis='y', labelcolor='b')\n",
    "    ax5_twin.tick_params(axis='y', labelcolor='r')\n",
    "    ax5.grid(alpha=0.3)\n",
    "    \n",
    "    lines = l1 + l2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax5.legend(lines, labels)\n",
    "\n",
    "# 6. Heatmap\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "metrics_matrix = np.array([prec, rec, hit, cov, div])\n",
    "im = ax6.imshow(metrics_matrix, cmap='YlOrRd', aspect='auto')\n",
    "ax6.set_xticks(range(len(names)))\n",
    "ax6.set_yticks(range(5))\n",
    "ax6.set_xticklabels(names, rotation=45, ha='right', fontsize=8)\n",
    "ax6.set_yticklabels(['Precision', 'Recall', 'Hit Rate', 'Coverage', 'Diversity'])\n",
    "ax6.set_title('Metrics Heatmap', fontweight='bold')\n",
    "plt.colorbar(im, ax=ax6)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(len(names)):\n",
    "        ax6.text(j, i, f'{metrics_matrix[i,j]:.3f}', ha='center', va='center', fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/comparison_sklearn.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('Saved: ../results/comparison_sklearn.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_prec = max(results['metrics'].items(), key=lambda x: x[1]['precision'])\n",
    "best_cov = max(results['metrics'].items(), key=lambda x: x[1]['coverage'])\n",
    "fastest = min(results['train_times'].items(), key=lambda x: x[1])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY (SKLEARN VERSION)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüèÜ Best Precision: {best_prec[0]} ({best_prec[1]['precision']:.4f})\")\n",
    "print(f\"üìä Best Coverage: {best_cov[0]} ({best_cov[1]['coverage']:.4f})\")\n",
    "print(f\"‚ö° Fastest: {fastest[0]} ({fastest[1]:.2f}s)\")\n",
    "\n",
    "svd_models = {k:v for k,v in results['metrics'].items() if 'SVD' in k}\n",
    "if svd_models:\n",
    "    best_svd = max(svd_models.items(), key=lambda x: x[1]['precision'])\n",
    "    print(f\"\\nüìà Best SVD: {best_svd[0]}\")\n",
    "    print(f\"   Precision: {best_svd[1]['precision']:.4f}\")\n",
    "    print(f\"   Time: {results['train_times'][best_svd[0]]:.1f}s\")\n",
    "    print(f\"   ‚úì sklearn SVD WORKS!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final thoughts\n",
    "\n",
    "*ƒêi·ªÅn ph√¢n t√≠ch cu·ªëi c√πng*\n",
    "\n",
    "#### sklearn vs code tay:\n",
    "- **Performance:** [so s√°nh]\n",
    "- **Speed:** [so s√°nh]\n",
    "- **Code simplicity:** sklearn r√µ r√†ng g·ªçn h∆°n r·∫•t nhi·ªÅu!\n",
    "- **Production ready:** sklearn ƒë∆∞·ª£c test k·ªπ v√† t·ªëi ∆∞u\n",
    "\n",
    "#### Recommended approach:\n",
    "1. **Prototype:** D√πng sklearn ƒë·ªÉ test nhanh\n",
    "2. **Production:** D√πng sklearn cho stability\n",
    "3. **Learning:** Code tay ƒë·ªÉ hi·ªÉu algorithm\n",
    "4. **Optimization:** N·∫øu sklearn kh√¥ng ƒë·ªß nhanh, m·ªõi optimize\n",
    "\n",
    "#### Key learnings:\n",
    "1. Sparse data c·∫ßn sparse algorithms\n",
    "2. sklearn TruncatedSVD perfect cho recommendation\n",
    "3. Kh√¥ng c·∫ßn reinvent the wheel\n",
    "4. Focus on problem solving, not implementation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../outputs/results_sklearn.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "df.to_csv('../outputs/comparison_sklearn.csv', index=False)\n",
    "\n",
    "print(\"‚úì Saved:\")\n",
    "print(\"  - results_sklearn.pkl\")\n",
    "print(\"  - comparison_sklearn.csv\")\n",
    "print(\"  - comparison_sklearn.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
