{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing - Amazon Beauty Ratings\n",
        "\n",
        "This notebook applies preprocessing pipeline to prepare data for recommendation system:\n",
        "- Handle missing values\n",
        "- Detect and handle outliers\n",
        "- Normalization and standardization\n",
        "- Feature engineering\n",
        "- Filter sparse data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.abspath('../src'))\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from data_loader import load_csv_numpy, validate_data, get_basic_stats\n",
        "from data_processing import (\n",
        "    detect_missing_values, impute_missing_mean, impute_missing_median,\n",
        "    detect_outliers_iqr, detect_outliers_zscore, remove_outliers,\n",
        "    normalize_minmax, normalize_log, standardize_zscore,\n",
        "    unix_to_datetime_features, filter_by_min_ratings\n",
        ")\n",
        "from feature_engineering import (\n",
        "    compute_user_stats, compute_product_stats,\n",
        "    compute_recency_score, compute_rating_velocity\n",
        ")\n",
        "\n",
        "np.random.seed(42)\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data, header = load_csv_numpy('../data/raw/ratings_Beauty.csv')\n",
        "print(f\"Original data shape: {data.shape}\")\n",
        "print(f\"Columns: {header}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Missing Values Handling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_report = detect_missing_values(data)\n",
        "print(\"Missing values check:\")\n",
        "for field, mask in missing_report.items():\n",
        "    missing_count = np.sum(mask)\n",
        "    print(f\"  {field}: {missing_count} missing values\")\n",
        "\n",
        "validation = validate_data(data)\n",
        "print(f\"\\nTotal nulls: {validation['total_nulls']}\")\n",
        "print(f\"Null percentage: {validation['null_percentage']:.2f}%\")\n",
        "\n",
        "if validation['total_nulls'] > 0:\n",
        "    print(\"\\nApplying mean imputation for numeric columns...\")\n",
        "    for field in data.dtype.names:\n",
        "        if np.issubdtype(data[field].dtype, np.number):\n",
        "            data[field] = impute_missing_mean(data, field)\n",
        "else:\n",
        "    print(\"\\nNo missing values found. Data is clean!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Outlier Detection and Handling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ratings = data['Rating']\n",
        "\n",
        "print(\"=== Outlier Detection ===\\n\")\n",
        "\n",
        "outliers_iqr = detect_outliers_iqr(ratings)\n",
        "outliers_zscore = detect_outliers_zscore(ratings, threshold=3.0)\n",
        "\n",
        "print(f\"IQR method: {np.sum(outliers_iqr)} outliers ({np.sum(outliers_iqr)/len(ratings)*100:.2f}%)\")\n",
        "print(f\"Z-score method: {np.sum(outliers_zscore)} outliers ({np.sum(outliers_zscore)/len(ratings)*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\nRating statistics:\")\n",
        "print(f\"  Mean: {np.mean(ratings):.4f}\")\n",
        "print(f\"  Std: {np.std(ratings):.4f}\")\n",
        "print(f\"  Min: {np.min(ratings):.1f}\")\n",
        "print(f\"  Max: {np.max(ratings):.1f}\")\n",
        "\n",
        "print(\"\\nNote: For ratings (1-5 scale), outliers are expected and may be valid.\")\n",
        "print(\"We will NOT remove outliers as they represent genuine user opinions.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Normalization and Standardization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Normalization Examples ===\\n\")\n",
        "\n",
        "ratings_sample = ratings[:1000]\n",
        "\n",
        "minmax_normalized = normalize_minmax(ratings_sample, feature_min=0, feature_max=1)\n",
        "log_normalized = normalize_log(ratings_sample, base='e')\n",
        "zscore_standardized = standardize_zscore(ratings_sample)\n",
        "\n",
        "print(\"Original ratings (sample):\")\n",
        "print(f\"  Range: [{np.min(ratings_sample):.2f}, {np.max(ratings_sample):.2f}]\")\n",
        "print(f\"  Mean: {np.mean(ratings_sample):.4f}, Std: {np.std(ratings_sample):.4f}\")\n",
        "\n",
        "print(\"\\nMin-Max Normalized:\")\n",
        "print(f\"  Range: [{np.min(minmax_normalized):.4f}, {np.max(minmax_normalized):.4f}]\")\n",
        "\n",
        "print(\"\\nLog Normalized:\")\n",
        "print(f\"  Range: [{np.min(log_normalized):.4f}, {np.max(log_normalized):.4f}]\")\n",
        "\n",
        "print(\"\\nZ-score Standardized:\")\n",
        "print(f\"  Mean: {np.mean(zscore_standardized):.4f}, Std: {np.std(zscore_standardized):.4f}\")\n",
        "\n",
        "print(\"\\nNote: For recommendation systems, we typically keep original ratings.\")\n",
        "print(\"Normalization may be applied to derived features if needed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Timestamp Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timestamps = data['Timestamp']\n",
        "datetime_features = unix_to_datetime_features(timestamps)\n",
        "\n",
        "print(\"=== Extracted Datetime Features ===\\n\")\n",
        "print(f\"Year range: {np.min(datetime_features['year'])} - {np.max(datetime_features['year'])}\")\n",
        "print(f\"Month range: {np.min(datetime_features['month'])} - {np.max(datetime_features['month'])}\")\n",
        "print(f\"Weekday distribution:\")\n",
        "unique_weekdays, weekday_counts = np.unique(datetime_features['weekday'], return_counts=True)\n",
        "for wd, count in zip(unique_weekdays, weekday_counts):\n",
        "    print(f\"  Weekday {wd}: {count:,} ratings ({count/len(timestamps)*100:.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Filter Sparse Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Filtering by Minimum Ratings ===\\n\")\n",
        "print(f\"Original data size: {len(data):,} ratings\")\n",
        "\n",
        "filtered_data = filter_by_min_ratings(\n",
        "    data, \n",
        "    min_user_ratings=5, \n",
        "    min_product_ratings=5\n",
        ")\n",
        "\n",
        "print(f\"Filtered data size: {len(filtered_data):,} ratings\")\n",
        "print(f\"Reduction: {(1 - len(filtered_data)/len(data))*100:.2f}%\")\n",
        "\n",
        "print(f\"\\nUnique users: {len(np.unique(filtered_data['UserId'])):,}\")\n",
        "print(f\"Unique products: {len(np.unique(filtered_data['ProductId'])):,}\")\n",
        "\n",
        "data = filtered_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Compute User and Product Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Computing User Statistics ===\\n\")\n",
        "user_stats = compute_user_stats(data)\n",
        "print(f\"Total users: {len(user_stats['user_id']):,}\")\n",
        "print(f\"Average ratings per user: {np.mean(user_stats['total_ratings']):.2f}\")\n",
        "print(f\"Average user rating: {np.mean(user_stats['avg_rating']):.4f}\")\n",
        "\n",
        "print(\"\\n=== Computing Product Statistics ===\\n\")\n",
        "product_stats = compute_product_stats(data)\n",
        "print(f\"Total products: {len(product_stats['product_id']):,}\")\n",
        "print(f\"Average ratings per product: {np.mean(product_stats['total_ratings']):.2f}\")\n",
        "print(f\"Average product rating: {np.mean(product_stats['avg_rating']):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Compute Recency and Velocity Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timestamps = data['Timestamp']\n",
        "\n",
        "recency_scores = compute_recency_score(timestamps, decay_factor=0.1)\n",
        "print(\"=== Recency Scores ===\\n\")\n",
        "print(f\"Recency score range: [{np.min(recency_scores):.4f}, {np.max(recency_scores):.4f}]\")\n",
        "print(f\"Mean recency: {np.mean(recency_scores):.4f}\")\n",
        "\n",
        "rating_velocity = compute_rating_velocity(timestamps, window_days=30)\n",
        "print(f\"\\n=== Rating Velocity (30-day windows) ===\\n\")\n",
        "print(f\"Number of windows: {len(rating_velocity)}\")\n",
        "print(f\"Average ratings per window: {np.mean(rating_velocity):.2f}\")\n",
        "print(f\"Max ratings in a window: {np.max(rating_velocity):.0f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save Processed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=== Saving Processed Data ===\\n\")\n",
        "\n",
        "output_dir = '../data/processed'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "np.save(f'{output_dir}/filtered_data.npy', data)\n",
        "np.save(f'{output_dir}/user_stats.npy', user_stats)\n",
        "np.save(f'{output_dir}/product_stats.npy', product_stats)\n",
        "\n",
        "print(f\"Saved:\")\n",
        "print(f\"  - {output_dir}/filtered_data.npy\")\n",
        "print(f\"  - {output_dir}/user_stats.npy\")\n",
        "print(f\"  - {output_dir}/product_stats.npy\")\n",
        "\n",
        "print(f\"\\nFinal processed data shape: {data.shape}\")\n",
        "print(f\"Final unique users: {len(np.unique(data['UserId'])):,}\")\n",
        "print(f\"Final unique products: {len(np.unique(data['ProductId'])):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Preprocessing pipeline completed:\n",
        "1. ✅ Missing values checked (none found)\n",
        "2. ✅ Outliers detected (kept as valid ratings)\n",
        "3. ✅ Normalization methods demonstrated\n",
        "4. ✅ Datetime features extracted\n",
        "5. ✅ Sparse data filtered (min 5 ratings per user/product)\n",
        "6. ✅ User and product statistics computed\n",
        "7. ✅ Recency and velocity features created\n",
        "8. ✅ Processed data saved\n",
        "\n",
        "Data is now ready for recommendation system modeling!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
